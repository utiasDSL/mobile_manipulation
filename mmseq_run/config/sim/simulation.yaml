simulation:
  timestep: 0.01
  duration: 25.
  gravity: [0, 0, -9.81]

  robot:
#    home: [0, 0, 0, 0.5pi, -0.5pi, 0, -0.pi, 0.5pi, 0]  # upright
#    home: [0, 0, 0, 0.5pi, 0., 0., 0., 0.5pi, 0.]  # upright
    home: [ 0., -0, 0.pi, 0.5pi, -0.25pi, 0.5pi, -0.25pi, 0.5pi, 0.417pi ]  # standard
#    home: [ -0., 0, 0.pi, 0.5pi, -0.25pi, 0.5pi, 0.25pi, 0.5pi, 0.417pi ]  # grasping box directly
    tool_vicon_name: ThingContainer

  pybullet_connection: "DIRECT"  # "Direct" or "GUI"

  static_obstacles:
    enabled: False

  dynamic_obstacles:
    enabled: False

  # Define virtual cameras to capture static shots of the scene or as a viewpoint
  # for a video. Examples:
  # 1. camera defined by (absolute) target and camera position;
  # 2. camera defined by a target and camera position *relative* to EE initial
  #    position;
  # 3. camera defined by a target position and distance and orientation of the
  #    camera (roll, pitch, yaw in degrees)
  cameras:
    example1:
      target: [4, 0, 0]
      position: [8, -3, 4]
      resolution:
        width: 1920
        height: 1080
    example2:
      relative_target: [0.0, 0, 0.7]
      relative_position: [5., -7., 6.]
    example3:
      target: [1.28, 0.045, 0.647]
      distance: 1.8
      roll: 0
      pitch: -29
      yaw: 147.6

  # Define videos to be captured during the simulation
  video:
    save_frames: false
    dir: "/home/tracy/Videos/MM-HTMPC/"
    timestep: 0.060
    views:
      -
        camera: example2
        name: view1

include:
  - package: "mmseq_run"
    path: "config/robot/thing.yaml"


